{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network structure\n",
    "global nn_structure,total_unknowns,act_fn,x,y\n",
    "\n",
    "nn_structure = [2,3,1]                                         # Number of nodes in layers :[Input_layer, hidden_layer1, output_layer]\n",
    "act_fn = ['logsig','logsig','logsig']                          # Activation function ; size should be same as nn_structure\n",
    "x = np.array([[0,0],[0,1],[1,0],[1,1]])                        # Input to neural network\n",
    "y = np.array([0,1,1,1])                                        # Output of neural network - OR Gate\n",
    "\n",
    "total_unknowns = 0\n",
    "for i in range(1,len(nn_structure)):\n",
    "    total_unknowns += (nn_structure[i]*nn_structure[i-1])      # adding weights of 'i'th layer\n",
    "    total_unknowns += nn_structure[i]                          # adding biases of 'i'th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "def log_sig(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def linear(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objective function\n",
    "\n",
    "def error(nn_params):   \n",
    "    pointer = 0\n",
    "    weights = []\n",
    "    biases = []\n",
    "    \n",
    "    # Extract layerwise weights and biases from particle position(nn_param)\n",
    "    for i in range(1,len(nn_structure)):\n",
    "        w = np.array(nn_params[pointer:(pointer+nn_structure[i]*nn_structure[i-1])]).reshape(nn_structure[i],nn_structure[i-1])\n",
    "        weights.append(w)\n",
    "        pointer += (nn_structure[i]*nn_structure[i-1])\n",
    "        \n",
    "        b = np.array(nn_params[pointer:(pointer+nn_structure[i])]).reshape(nn_structure[i],1)\n",
    "        biases.append(b)\n",
    "        pointer += nn_structure[i]\n",
    "    \n",
    "    # Predict output variable\n",
    "    y_pred = []\n",
    "    for inp in x:\n",
    "        prev_layer = inp.reshape(1,2).T\n",
    "        for layer in range(len(weights)):\n",
    "            prev_layer = weights[layer]@prev_layer + biases[layer]\n",
    "            activation = act_fn[layer]\n",
    "            if activation == 'logsig':\n",
    "                prev_layer = log_sig(prev_layer)\n",
    "            elif activation == 'linear':\n",
    "                prev_layer = linear(prev_layer)\n",
    "        y_pred.append(prev_layer[0][0])\n",
    "    \n",
    "    # Calculate error value. We can use RMSE / absolute mean error. \n",
    "    rmse = mean_squared_error(y_pred,y.flatten())    \n",
    "    return 10*rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self):\n",
    "        self.position = np.random.rand(total_unknowns) #We initialize position randomly in 6(w1) + 3(b1) + 3(w2) + 1(b2) = 13 dimension space\n",
    "        self.velocity = np.random.rand(total_unknowns) #Initialize velocity randomly\n",
    "        self.cost = error(self.position)               #Calculate cost value associated with position of particle\n",
    "        self.best_position = self.position             #Initialize local best as current position\n",
    "        self.best_cost = 100000000                     #Initialize best cost\n",
    "\n",
    "class GlobalBest:                                      #Initialize global best\n",
    "    def __init__(self):\n",
    "        self.position = np.random.rand(13)\n",
    "        self.cost = 100000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSO param initialization\n",
    "swarm_size = 10\n",
    "iteration = 15\n",
    "list_of_particles = []\n",
    "global_best = GlobalBest()\n",
    "\n",
    "for i in range(swarm_size):\n",
    "    particle = Particle()\n",
    "    if particle.cost < global_best.cost:\n",
    "        global_best.cost = particle.cost\n",
    "        global_best.position = particle.position  \n",
    "    list_of_particles.append(particle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main PSO\n",
    "w = 0.3\n",
    "c1 = 0.50\n",
    "c2 = 0.64\n",
    "for itr in range(iteration):\n",
    "    #print(\"Iteration :\",itr)\n",
    "    for particle in list_of_particles:\n",
    "        #Calculate new velocity\n",
    "        newVelocity = (w*particle.velocity) + (round(c1*(-3 + 6*random.random()))*(particle.best_position - particle.position)) + (round(c2*(-3 + 6*random.random()))*(global_best.position - particle.position))\n",
    "\n",
    "        #Calculate new position\n",
    "        newPosition = particle.position + newVelocity\n",
    "\n",
    "        current_cost = error(particle.position)\n",
    "        new_cost = error(newPosition)\n",
    "\n",
    "        if new_cost < current_cost:\n",
    "            # Update velocity,position,cost\n",
    "            particle.velocity = newVelocity\n",
    "            particle.position = newPosition\n",
    "            particle.cost = new_cost\n",
    "\n",
    "            # Upodate local best\n",
    "            if particle.cost < particle.best_cost:\n",
    "                particle.best_position = particle.position;\n",
    "                particle.best_cost = particle.cost;\n",
    "\n",
    "                #Update global best\n",
    "                if particle.best_cost < global_best.cost:\n",
    "                    global_best.cost = particle.best_cost\n",
    "                    global_best.position = particle.position                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.958213330234088e-05\n"
     ]
    }
   ],
   "source": [
    "print(global_best.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output : [2.4265442176783237e-14, 0.9967426117622791, 0.9967424400146043, 0.9967426117622791]\n",
      "Actual output : [0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# predict output using trained neural network\n",
    "\n",
    "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,1,1,1])\n",
    "nn_params = global_best.position\n",
    "pointer = 0\n",
    "weights = []\n",
    "biases = []\n",
    "for i in range(1,len(nn_structure)):\n",
    "    w = np.array(nn_params[pointer:(pointer+nn_structure[i]*nn_structure[i-1])]).reshape(nn_structure[i],nn_structure[i-1])\n",
    "    weights.append(w)\n",
    "    pointer += (nn_structure[i]*nn_structure[i-1])\n",
    "\n",
    "    b = np.array(nn_params[pointer:(pointer+nn_structure[i])]).reshape(nn_structure[i],1)\n",
    "    biases.append(b)\n",
    "    pointer += nn_structure[i]\n",
    "\n",
    "y_pred = []\n",
    "for inp in x:\n",
    "    prev_layer = inp.reshape(1,2).T\n",
    "    for layer in range(len(weights)):\n",
    "        prev_layer = weights[layer]@prev_layer + biases[layer]\n",
    "        activation = act_fn[layer]\n",
    "        if activation == 'logsig':\n",
    "            prev_layer = log_sig(prev_layer)\n",
    "        elif activation == 'linear':\n",
    "            prev_layer = linear(prev_layer)\n",
    "    y_pred.append(prev_layer[0][0])\n",
    "print(\"Predicted output :\",y_pred)\n",
    "print(\"Actual output :\",y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
